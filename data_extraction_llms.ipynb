{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --quiet langchain langchain-community langchain-openai chromadb \n",
    "!pip3 install --upgrade --quiet pypdf pandas streamlit python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langchain modules\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Other modules and packages\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st  \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPEN_AI_API_KEY = os.environ.get(\"OPEN_AI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and load all PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "# Traverse the directory tree and collect specified file in the ./data folder\n",
    "loader = PyPDFLoader(\"data/Ubisoft_FY25_Q1_Sales_EN_vFinal.pdf\")\n",
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, \n",
    "                                               chunk_overlap=120, \n",
    "                                               length_function=len, \n",
    "                                               separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use embedding function from OpenAI\n",
    "embedding_function = embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\", openai_api_key=OPEN_AI_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and populate vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(documents, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Create a list of unique ids for each document based on the content\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in documents]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_documents = []\n",
    "    \n",
    "    for doc, id in zip(documents, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_documents.append(doc) \n",
    "\n",
    "    # Create a new Chroma database from the unique_documents\n",
    "    chromaDB = Chroma.from_documents(documents=unique_documents, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function, \n",
    "                                        persist_directory = vectorstore_path)\n",
    "\n",
    "    chromaDB.persist()\n",
    "    \n",
    "    return chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = create_vectorstore(documents=documents, \n",
    "                                 embedding_function=embedding_function, \n",
    "                                 vectorstore_path=\"vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query for relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorstore\n",
    "vectorstore = Chroma(persist_directory=\"vectorstore_test\", \n",
    "                     embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever and get relevant chunks\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "question = \"What is the title of this fiscal year (FY) quarter (Q) result report?\"\n",
    "\n",
    "relevant_chunks = retriever.invoke(question)\n",
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate structured responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPEN_AI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\n",
    "Additionally, if found in the context, provide the following:\n",
    "- Revenue and Earnings: Assess year-over-year (YoY) or quarter-over-quarter (QoQ) growth.\n",
    "- Profit Margins: Review operating and net profit margins for efficiency.\n",
    "- Expenses: Compare R&D, marketing, and operating costs to previous periods.\n",
    "- Cash Flow: Check operational cash flow for liquidity and sustainability.\n",
    "- Balance Sheet: Analyze assets, liabilities, and equity for financial health.\n",
    "- Forward Guidance: Look for management's projections or economic outlook.\n",
    "- Key Metrics: Industry-specific data (e.g., customer growth, product sales).\n",
    "- Trends: Spot patterns or anomalies over time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate context text\n",
    "context_text = \"\\n\\n---\\n\\n\".join(\n",
    "    [f\"Page {doc.metadata['page']}:\\n{doc.page_content}\" for doc in relevant_chunks]\n",
    ")\n",
    "\n",
    "# Create prompt\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "\n",
    "prompt = prompt_template.format(context=context_text, question=question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model for reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithSources(BaseModel):\n",
    "    \"\"\"An answer to the question, with sources and reasoning\"\"\"\n",
    "    answer: str = Field(description=\"Answer to question\")\n",
    "    sources: str = Field(description=\"Full direct text chunk from the context used to answer the question\")\n",
    "    reasoning: str = Field(description=\"Explain the reasoning of the answer based on the sources\")\n",
    "    \n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted information about the report\"\"\"\n",
    "    report_company_name: AnswerWithSources\n",
    "    report_summary: AnswerWithSources\n",
    "    revenue_and_earnings: AnswerWithSources\n",
    "    profit_margins: AnswerWithSources\n",
    "    expenses: AnswerWithSources\n",
    "    cash_flow: AnswerWithSources\n",
    "    balance_sheet: AnswerWithSources\n",
    "    forward_guidance: AnswerWithSources\n",
    "    key_metrics: AnswerWithSources\n",
    "    trends: AnswerWithSources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Langchain Expression Language\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n---\\n\\n\".join(\n",
    "    [f\"Page {doc.metadata['page']}:\\n{doc.page_content}\" for doc in relevant_chunks]\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    "        )\n",
    "\n",
    "structured_response = rag_chain.invoke(\"Give me the company name, summary, and details about revenue, profit margins, expenses, cash flow, balance sheet, forward guidance, key metrics, and trends from the fiscal year (FY) quarter (Q) result report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
